{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor, NearestNeighbors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "pred_data = pd.read_csv('promotion_schedule.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>t</th>\n",
       "      <th>price</th>\n",
       "      <th>advertised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.137451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3.023893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i   j  t     price  advertised\n",
       "0  4   7  0  2.137451           0\n",
       "1  6   1  0  0.863341           0\n",
       "2  8   6  0  0.799155           0\n",
       "3  8  25  0  3.023893           0\n",
       "4  9   6  0  0.799155           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data) == len(train_data_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean, Add & Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create past add lookup\n",
    "ad_lookup = pd.DataFrame(columns=['j', 't', 'ad'])\n",
    "for j in range(40):\n",
    "    for t in range(49):\n",
    "        foo = train_data[ (train_data.j == j) & (train_data.t == t) ]\n",
    "        if len(foo) == 0:\n",
    "            ad_lookup = ad_lookup.append({'j': j, 't': t, 'ad': 0}, ignore_index=True)\n",
    "        else:\n",
    "            for index, row in foo.iterrows():\n",
    "                ad = row['advertised']\n",
    "                ad_lookup = ad_lookup.append({'j': j, 't': t, 'ad': int(ad)}, ignore_index=True)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 0 values\n",
    "train_data_update = train_data.copy()\n",
    "for i in range(2000):\n",
    "    for j in range(40):\n",
    "        for t in range(49):\n",
    "            if len(train_data[ (train_data.i == i) & (train_data.j == j) & (train_data.t == t) ]) == 0:\n",
    "                ad = ad_lookup[ (ad_lookup.j == j) & (ad_lookup.t == t)].ad.values[0]\n",
    "                train_data_update = train_data_update.append({'i': i, 'j': j, 't': t, 'price': 0, 'advertised': ad}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_update.to_pickle('train_data_update.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy the categories\n",
    "foo = pd.get_dummies(train_data_update, columns=['j', 'i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and y\n",
    "y = foo.pop('price')\n",
    "X = foo\n",
    "del foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_split(X, y, test_start_time):\n",
    "    '''\n",
    "    Splits data based on a sinlge point in time\n",
    "    '''\n",
    "    train_index = X.t < test_start_time\n",
    "    test_index = X.t >= test_start_time\n",
    "    X_train, y_train = X[ train_index], y[ train_index]\n",
    "    X_test, y_test = X[ test_index ], y[ test_index ]\n",
    "    print('Data used to test: {} %'.format(round(len(y_test) / ( len(y_test) + len(y_train) ), 3) * 100))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "split_by_time = True\n",
    "if split_by_time:\n",
    "    X_train, X_test, y_train, y_test = time_split(X, y, 39)\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X_km, clusters):\n",
    "    SSE_arr = []\n",
    "    ss_arr = []\n",
    "    for i in clusters:\n",
    "        kmeans = KMeans(n_clusters=i, n_jobs=-1)\n",
    "        clust_dist = kmeans.fit_transform(X_km)\n",
    "        clust_num = kmeans.predict(X_km)\n",
    "\n",
    "        SSE = 0\n",
    "        for a, b in zip(clust_dist, clust_num):\n",
    "            SSE += a[b] ** 2\n",
    "        SSE_arr.append(SSE)\n",
    "\n",
    "        if i > 1:\n",
    "            ss_arr.append(silhouette_score(X_km, clust_num))\n",
    "    return SSE_arr, ss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_plot(SSE_arr, clusters):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title('Elbow Plot')\n",
    "    plt.plot(clusters, SSE_arr)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.xticks(clusters)\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Sum of Squares Error (SSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_plot(ss_arr, clusters):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title('Silhouette Scores')\n",
    "    plt.plot(clusters, ss_arr)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.xticks(clusters)\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Silhouette Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['j_{}'.format(i) for i in range(0, 40)]\n",
    "customer_df = pd.DataFrame(np.zeros((2000, 40)), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_data.iterrows():\n",
    "    price = row['price']\n",
    "    j = int(row['j'])\n",
    "    i = int(row['i'])\n",
    "    customer_df.iloc[i]['j_{}'.format(j)] += price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusts = 100\n",
    "clusters = np.arange(1, num_clusts)\n",
    "sil_clusters = np.arange(2, num_clusts)\n",
    "SSE_arr, ss_arr = kmeans(customer_df, clusters)\n",
    "elbow_plot(SSE_arr, clusters)\n",
    "silhouette_plot(ss_arr, sil_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=7)\n",
    "pred = kmeans.fit_predict(customer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2).fit_transform(customer_df)\n",
    "plt.scatter(pca[:,0], pca[:,1], c=pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(model, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Determine negative mean absolute error for test data\n",
    "    '''\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    return -abs(np.array(pred) - np.array(y_test)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_crossval_plot(X_train, X_test, y_train, y_test, models, splits=6, scoring='neg_mean_absolute_error'):\n",
    "    \"\"\"\n",
    "    Create violin plot of multiple models' test scores\n",
    "    Inputs:\n",
    "        X - dataframe features\n",
    "        y - dataframe target column\n",
    "        models - list of sklearn models to test\n",
    "        scoring - measure of best fit for models to use\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    names = []\n",
    "    all_scores = []\n",
    "    print('Mod - Avg - Std Dev')\n",
    "    print('---   ---   -------')\n",
    "    for model in models:\n",
    "        name = model.__class__.__name__\n",
    "        kfold = KFold(n_splits=splits)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring, n_jobs=-1)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        print('{}: {:.4f} ({:4f})'.format(name, cv_results.mean(), cv_results.std()))\n",
    "        print('Test acc: {:.4f}'.format(test_acc(model, X_train, X_test, y_train, y_test)))\n",
    "        print()\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle('Cross Validation Comparison of Regression Models')\n",
    "    ax = fig.add_subplot(111)\n",
    "    sb.violinplot(data=results, orient='v')\n",
    "    ax.set_xticklabels(names, rotation=50, ha='right')\n",
    "    ax.set_xlabel('Model')\n",
    "    plt.grid(alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Cross Validation\n",
    "models = []\n",
    "# models.append(Ridge())\n",
    "# models.append(KNeighborsRegressor(n_jobs=-1))\n",
    "# models.append(DecisionTreeRegressor())\n",
    "models.append(RandomForestRegressor(n_jobs=3))\n",
    "models.append(ExtraTreesRegressor(n_jobs=3))\n",
    "# models.append(GradientBoostingRegressor())\n",
    "# models.append(MLPRegressor())\n",
    "\n",
    "class_crossval_plot(X_train, X_test, y_train, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clust_grid(model, params, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Grid search over model\n",
    "    Inputs:\n",
    "        model - sklearn model to use (ie Lasso())\n",
    "        params - parameter grid to search over for each model\n",
    "        X_train - features to train model with\n",
    "        y_train - targets to validate model with\n",
    "    Returns:\n",
    "        list of the best parameters found by the grid search\n",
    "    \"\"\"\n",
    "    test_model = model\n",
    "    grid = GridSearchCV(test_model, param_grid=params, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    return grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search RF\n",
    "rf = RandomForestRegressor()\n",
    "params = {'n_estimators': [10, 30], 'max_features': ['auto', 0.3], 'min_samples_split': [2, 4], 'n_jobs': [-1]}\n",
    "best_params, best_score = clust_grid(rf, params, X_train, y_train)\n",
    "print(best_params)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search ET\n",
    "et = ExtraTreesRegressor()\n",
    "params = {'n_estimators': [10, 30], 'max_features': ['auto', 0.3], 'n_jobs': [-1]}\n",
    "best_params, best_score = clust_grid(et, params, X_train, y_train)\n",
    "print(best_params)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pred_data.set_index('j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_50 = pd.DataFrame(columns=['i', 'j', 't', 'advertised'])\n",
    "t = 49 # first week is 0, so 49 represents week 50\n",
    "for i in range(0, 2000):\n",
    "    for index, row in pred_data.iterrows():\n",
    "        advertised = row['advertised']\n",
    "        week_50 = week_50.append({'i': int(i), 'j': int(index), 't': int(t), 'advertised': int(advertised)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_week_50 = pd.get_dummies(week_50, columns=['j', 'i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_week_50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_model = ExtraTreesRegressor(n_estimators=30, max_features='auto', n_jobs=-1)\n",
    "rf_model = RandomForestRegressor(n_estimators=30, min_samples_split=4, max_features='auto', n_jobs=-1)\n",
    "\n",
    "et_model.fit(X, y)\n",
    "rf_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_weight = 0.5\n",
    "et_pred = et_model.predict(dummy_week_50)\n",
    "rf_pred = rf_model.predict(dummy_week_50)\n",
    "final_pred = et_weight * et_pred + (1 - et_weight) * rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_predictions.csv', 'w+') as f:\n",
    "    f.write('i,j,prediction\\n')\n",
    "    for index, row in week_50.iterrows():\n",
    "        i = row['i']\n",
    "        j = row['j']\n",
    "        pred = final_pred[index]\n",
    "        f.write('{},{},{}\\n'.format(i, j, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = train_data[ train_data.i == 0 ]\n",
    "for j in foo.j.unique():\n",
    "    bar = foo[ foo.j == j ]\n",
    "    plt.plot(bar.t, bar.price, label=j)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
